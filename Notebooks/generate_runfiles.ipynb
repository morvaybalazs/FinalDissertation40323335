{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `make_runfile` Function Explanation\n",
    "\n",
    "This code defines a function called `make_runfile` that takes four arguments: `input_file_path`, `output_dir`, `output_file_name`, and `run_tag`. \n",
    "The function reads data from the input file, processes the lines, sorts the data by topic ID and score, and writes the sorted data to the output file.\n",
    "\n",
    "## Steps\n",
    "\n",
    "### 1. Create the Output Directory\n",
    "\n",
    "If the output directory doesn't exist, it is created using the `os.makedirs` function with the `exist_ok=True` flag.\n",
    "\n",
    "### 2. Read the Input File\n",
    "\n",
    "The input file is read, and the lines are stored in a list called `lines`.\n",
    "\n",
    "### 3. Process the Lines\n",
    "\n",
    "Each line is processed using regular expressions to extract the score, topic ID, argument ID, and rank. These values are stored in a list of dictionaries called `data`.\n",
    "\n",
    "### 4. Sort the Data\n",
    "\n",
    "The data is sorted by topic ID (low to high) and score (high to low). The score is converted to a float to ensure proper sorting.\n",
    "\n",
    "### 5. Write the Sorted Data to the Output File\n",
    "\n",
    "The sorted data is written to the output file. Each line in the output file contains the topic ID, a fixed value of 0, the argument ID, the score, and the run tag, all separated by spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "data_path = '/Users/balazs/Desktop/dissertationProjectCode/dissertationCodeBase/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_runfile(input_file_path, output_dir, output_file_name, run_tag):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Set the output file path\n",
    "    output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "    # Read the input file and store the lines in a list\n",
    "    with open(input_file_path, 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "\n",
    "    # Process the lines and store them in a list of dictionaries\n",
    "    data = []\n",
    "    seen = set()\n",
    "    for line in lines:\n",
    "        score = re.search(r'^([\\d.]+)', line).group(1)\n",
    "        topic_id = re.search(r'qid:(\\d+)', line).group(1)\n",
    "        argument_id = re.search(r'#(.+)$', line).group(1)\n",
    "\n",
    "        # Skip duplicates\n",
    "        if (topic_id, argument_id) in seen:\n",
    "            continue\n",
    "        seen.add((topic_id, argument_id))\n",
    "        \n",
    "        data.append({\n",
    "            'score': score,\n",
    "            'topic_id': topic_id,\n",
    "            'argument_id': argument_id\n",
    "        })\n",
    "\n",
    "    # Sort the data by topic_id (low to high) and score (high to low)\n",
    "    data.sort(key=lambda x: (int(x['topic_id']), -float(x['score'])))\n",
    "\n",
    "    # Write the sorted data to the output file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for i, item in enumerate(data):\n",
    "            topic_id = item['topic_id']\n",
    "            argument_id = item['argument_id']\n",
    "            score = item['score']\n",
    "            rank = i + 1\n",
    "            output_line = f\"{topic_id}\\t0\\t{argument_id}\\t{rank}\\t{score}\\t{run_tag}\\n\"\n",
    "            f.write(output_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate runfiles linguistic sentiment\n",
    "input_file_path_2020 = data_path + \"Data/re_ranked_2020_2021/linguistic_sentiment_re_ranked/re_ranked_2020_LambdaMart.txt\"\n",
    "input_file_path_2021 = data_path + \"Data/re_ranked_2020_2021/linguistic_sentiment_re_ranked/re_ranked_2021_LambdaMart.txt\"\n",
    "\n",
    "output_dir = data_path + \"Data/runfiles_2020_2021/linguistic_sentiment_runfiles\"\n",
    "\n",
    "output_file_name_2020 =  \"runfile_2020_LambdaMart.txt\"\n",
    "output_file_name_2021 =  \"runfile_2021_LambdaMart.txt\"\n",
    "\n",
    "run_tag_2020 = \"linguistic_sentiment_2020_LambdaMart\"\n",
    "run_tag_2021 = \"linguistic_sentiment_2021_LambdaMart\"\n",
    "\n",
    "\n",
    "make_runfile(input_file_path_2020, output_dir, output_file_name_2020, run_tag_2020)\n",
    "make_runfile(input_file_path_2021, output_dir, output_file_name_2021, run_tag_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate runfiles sbert\n",
    "input_file_path_2020 = data_path + \"Data/re_ranked_2020_2021/sbert_re_ranked/re_ranked_2020_LambdaMart.txt\"\n",
    "input_file_path_2021 = data_path + \"Data/re_ranked_2020_2021/sbert_re_ranked/re_ranked_2021_LambdaMart.txt\"\n",
    "\n",
    "output_dir = data_path + \"Data/runfiles_2020_2021/sbert_runfiles\"\n",
    "\n",
    "output_file_name_2020 =  \"runfile_2020_LambdaMart.txt\"\n",
    "output_file_name_2021 =  \"runfile_2021_LambdaMart.txt\"\n",
    "\n",
    "run_tag_2020 = \"SBERT_2020_LambdaMart\"\n",
    "run_tag_2021 = \"SBERT_2021_LambdaMart\"\n",
    "\n",
    "\n",
    "make_runfile(input_file_path_2020, output_dir, output_file_name_2020, run_tag_2020)\n",
    "make_runfile(input_file_path_2021, output_dir, output_file_name_2021, run_tag_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate runfiles linguistic sarcasm\n",
    "input_file_path_2020 = data_path + \"Data/re_ranked_2020_2021/sentiment_sarcasm_re_ranked/re_ranked_2020_LambdaMart.txt\"\n",
    "input_file_path_2021 = data_path + \"Data/re_ranked_2020_2021/sentiment_sarcasm_re_ranked/re_ranked_2021_LambdaMart.txt\"\n",
    "\n",
    "output_dir = data_path + \"Data/runfiles_2020_2021/sentiment_sarcasm_runfiles\"\n",
    "\n",
    "output_file_name_2020 =  \"runfile_2020_LambdaMart.txt\"\n",
    "output_file_name_2021 =  \"runfile_2021_LambdaMart.txt\"\n",
    "\n",
    "run_tag_2020 = \"sarcasm_sentiment_2020_LambdaMart\"\n",
    "run_tag_2021 = \"sarcasm_sentiment_2021_LambdaMart\"\n",
    "\n",
    "\n",
    "make_runfile(input_file_path_2020, output_dir, output_file_name_2020, run_tag_2020)\n",
    "make_runfile(input_file_path_2021, output_dir, output_file_name_2021, run_tag_2021)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate baseline runfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = data_path + 'Data/arguments_retrieved_2020'\n",
    "output_file = data_path + 'Data/runfiles_2020_2021/baseline_runfiles/baseline_runfile_2020.txt'\n",
    "tag = 'baseline_runfile_2020'\n",
    "\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        merged_df = pd.concat([merged_df, df])\n",
    "\n",
    "merged_df['Tag'] = tag\n",
    "merged_df['Q0'] = 'Q0'\n",
    "merged_df['Rank'] = merged_df.groupby('qid')['score'].rank(ascending=False)\n",
    "merged_df = merged_df[['qid', 'Q0', 'docno', 'Rank', 'score', 'Tag']]\n",
    "merged_df.columns = ['Topic', 'Q0', 'ID', 'Rank', 'Score', 'Tag']\n",
    "merged_df.sort_values(by=['Topic', 'Rank'], ascending=[True, True], inplace=True)\n",
    "merged_df.to_csv(output_file, sep=' ', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
